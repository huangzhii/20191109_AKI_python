5 fold CV -- 1/5
5 fold CV -- 2/5
5 fold CV -- 3/5
5 fold CV -- 4/5
5 fold CV -- 5/5
Current model: GBM, current hyper-parameter: 8, current F1 score: 0.73130087; current sensitivity: 0.90605067
5 fold CV -- 1/5
5 fold CV -- 2/5
5 fold CV -- 3/5
5 fold CV -- 4/5
5 fold CV -- 5/5
Current model: GBM, current hyper-parameter: 16, current F1 score: 0.74343965; current sensitivity: 0.87838985
5 fold CV -- 1/5
5 fold CV -- 2/5
5 fold CV -- 3/5
5 fold CV -- 4/5
5 fold CV -- 5/5
Current model: GBM, current hyper-parameter: 32, current F1 score: 0.75133066; current sensitivity: 0.85745414
5 fold CV -- 1/5
5 fold CV -- 2/5
5 fold CV -- 3/5
5 fold CV -- 4/5
5 fold CV -- 5/5
Current model: GBM, current hyper-parameter: 64, current F1 score: 0.75497490; current sensitivity: 0.82122194
5 fold CV -- 1/5
5 fold CV -- 2/5
5 fold CV -- 3/5
5 fold CV -- 4/5
5 fold CV -- 5/5
Current model: GBM, current hyper-parameter: 128, current F1 score: 0.74984774; current sensitivity: 0.77436616
5 fold CV -- 1/5
5 fold CV -- 2/5
5 fold CV -- 3/5
5 fold CV -- 4/5
5 fold CV -- 5/5
Current model: GBM, current hyper-parameter: 256, current F1 score: 0.73998548; current sensitivity: 0.71024347
Best hyper-parameter: 64
Model:
GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_impurity_split=None,
                           min_samples_leaf=1, min_samples_split=2,
                           min_weight_fraction_leaf=0.0, n_estimators=64,
                           n_iter_no_change=None, presort='deprecated',
                           random_state=None, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
[MIMIC] train AUC: 0.88207840, test AUC: 0.84233907, train F1: 0.79643506, test F1: 0.76797964, test Precision: 0.77366578, test Recall: 0.76808223, sensitivity: 0.83420776, specificity: 0.70195669, PPV: 0.74565247, NPV: 0.80167908
[EICU] test AUC: 0.71809912, test F1: 0.43819877, test Precision: 0.51127437, test Recall: 0.64630134
