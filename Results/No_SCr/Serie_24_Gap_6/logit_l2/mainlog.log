5 fold CV -- 1/5
5 fold CV -- 2/5
5 fold CV -- 3/5
5 fold CV -- 4/5
5 fold CV -- 5/5
Current model: logit_l2, current hyper-parameter: 0.5, current F1 score: 0.69135308; current sensitivity: 0.71755946
5 fold CV -- 1/5
5 fold CV -- 2/5
5 fold CV -- 3/5
5 fold CV -- 4/5
5 fold CV -- 5/5
Current model: logit_l2, current hyper-parameter: 1, current F1 score: 0.69136615; current sensitivity: 0.71755946
5 fold CV -- 1/5
5 fold CV -- 2/5
5 fold CV -- 3/5
5 fold CV -- 4/5
5 fold CV -- 5/5
Current model: logit_l2, current hyper-parameter: 1.5, current F1 score: 0.69135218; current sensitivity: 0.71755946
5 fold CV -- 1/5
5 fold CV -- 2/5
5 fold CV -- 3/5
5 fold CV -- 4/5
5 fold CV -- 5/5
Current model: logit_l2, current hyper-parameter: 2, current F1 score: 0.69137193; current sensitivity: 0.71755946
5 fold CV -- 1/5
5 fold CV -- 2/5
5 fold CV -- 3/5
5 fold CV -- 4/5
5 fold CV -- 5/5
Current model: logit_l2, current hyper-parameter: 2.5, current F1 score: 0.69137253; current sensitivity: 0.71755946
5 fold CV -- 1/5
5 fold CV -- 2/5
5 fold CV -- 3/5
5 fold CV -- 4/5
5 fold CV -- 5/5
Current model: logit_l2, current hyper-parameter: 3, current F1 score: 0.69135642; current sensitivity: 0.71755946
Best hyper-parameter: 2.5
Model:
LogisticRegression(C=2.5,
                   class_weight={0: 6.26491833678948e-06,
                                 1: 6.26491833678948e-06},
                   dual=False, fit_intercept=True, intercept_scaling=1,
                   l1_ratio=None, max_iter=100, multi_class='auto', n_jobs=-1,
                   penalty='l2', random_state=None, solver='saga', tol=0.0001,
                   verbose=0, warm_start=False)
[MIMIC] train AUC: 0.77590717, test AUC: 0.75211626, train F1: 0.69509724, test F1: 0.67554619, test Precision: 0.67936478, test Recall: 0.67640140, sensitivity: 0.73879025, specificity: 0.61401254, PPV: 0.66234993, NPV: 0.69637964
[EICU] test AUC: 0.60260941, test F1: 0.45184049, test Precision: 0.50516620, test Recall: 0.54986870
